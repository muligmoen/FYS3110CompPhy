\documentclass[11pt,a4paper,draft]{article}
\usepackage[english]{babel} % Using babel for hyphenation
\usepackage{lmodern} % Changing the font
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}


\usepackage[colorlinks=true]{hyperref}
\usepackage{cleveref}

%\usepackage[moderate]{savetrees} % [subtle/moderate/extreme] really compact writing
\usepackage{framed}
\usepackage{tcolorbox}
\tcbuselibrary{hooks}
\usepackage[parfill]{parskip} % Removes indents
\usepackage{amsmath} % Environment, symbols etc...
\usepackage{amssymb}
\usepackage{float} % Fixing figure locations
\usepackage{multirow} % For nice tables
%\usepackage{wasysym} % Astrological symbols
\usepackage{graphicx} % For pictures etc...
\usepackage{enumitem} % Points/lists
\usepackage{physics} % Typesetting of mathematical physics examples: 
                     % \bra{}, \ket{}, expval{}
\usepackage{url}


\usepackage{caption}
\usepackage{subcaption}

\definecolor{red}{RGB}{255,10,10}

% To include code(-snippets) with æøå
\usepackage{listings}
\lstset{
language=c++,
showspaces=false,
showstringspaces=false,
frame=l,
}

\tolerance = 5000 % Bedre tekst
\hbadness = \tolerance
\pretolerance = 2000

\numberwithin{equation}{section}

\newcommand{\conj}[1]{#1^*}
\newcommand{\ve}[1]{\mathbf{#1}} % Vektorer i bold
\let\oldhat\hat
\renewcommand{\hat}[1]{\oldhat{#1}}
\newcommand{\trans}[1]{#1^\top}
\newcommand{\herm}[1]{#1^\dagger}

\newcommand{\Real}{\mathbb{R}}
\newcommand{\bigO}[1]{\mathcal{O}\left( #1 \right)}

\newcommand{\di}{\mathrm{d}}
\newcommand{\magM}{\mathcal{M}}

\newcounter{algcounter}
\renewcommand{\thealgcounter}{\Roman{algcounter}}

\newenvironment{algorithm}{%
\refstepcounter{algcounter}
\begin{tcolorbox}
\centerline{Algorithm \thealgcounter}\vspace{2mm}
}
{\end{tcolorbox}}

\newcommand{\figurewidth}{.85\textwidth}

\title{FYS3150/4150\\Computational Physics\\Project 5}
\author{Magnus Ulimoen \& Krister Stræte Karlsen\\
Candidate numbers 33 \& 63}
\date{\today}

\begin{document}
\tcbset{before app=\parfillskip0pt}
\maketitle

\section{Mathematical problem}

\begin{gather}
\frac{\partial u}{\partial t} = D\nabla^2u
\end{gather}
One dimensional,
\subsection{Boundary conditions}
Interval $x \in (0, d)$
\begin{align}
u(0,t) &= u_0\\
u(d,t) &= 0\\
u(x,0) &= 0
\end{align}

\subsection{Scaling}

To shrink the range of x, we introduce the length scaling,
\begin{gather}
\tilde{x} = \frac{x}{d}
\end{gather}
And a time scaling
\begin{gather}
\tilde{t} = t\frac{D}{d^2}
\end{gather}
And scaling the function
\begin{gather}
\tilde{u}(x,t) = \frac{u(x,t)}{u_0}
\end{gather}
Our equation then takes the simple form
\begin{gather}
\frac{\partial \tilde{u}}{\partial \tilde{t}}
= \frac{\partial \tilde{u}^2}{\partial \tilde{x}^2}\\
0 \le \tilde{x} \le 1\\
\tilde{u}(0,\tilde{t})
= 1, \quad \tilde{u}(1,\tilde{t}) = 0, \quad \tilde{u}(\tilde{x}, 0 ) = 0
\end{gather}
In the next sections we will drop the tilde and work with the 
dimensionless parameters.





\section{Closed form}
In steady state
\begin{gather}
\frac{\partial^2 u_s}{\partial x^2} = 0\\
u_s(x) = Ax + b\\
u_s(0) \to b = 1, \quad
u_s(1) \to A = -1\\
u_s(x) = 1-x
\end{gather}
Defining new non-steady solution
\begin{gather}
v(x,t) = u(x,t) - u_s(x)\\
v(x,0) = -u_s(x)\\
v(0,t) = 0, \quad v(1, t) = 0
\end{gather}

This equation can be assumed to be on the form
\begin{gather}
v(x,t) = X(x)T(t)
\end{gather}
And so
\begin{gather}
\frac{\partial^2 X(x)T(t)}{\partial x^2}
= \frac{\partial X(x)T(t)}{\partial t}\\
\frac{1}{X(x)}\frac{\partial^2 X(x)}{\partial x^2}
 = \frac{1}{T(t)}\frac{\partial T(t)}{\partial t} = C
 \label{eq:coupled_constant}
\end{gather}
The solution to these two equations are 
\begin{gather}
X(x) = e^{\pm i\pi kx}\\
T(t) = e^{\pm at}
\end{gather}
Since $T(t)$ can not grow to infinity, only the solution with a 
negative exponential is 
allowed. Now using \eqref{eq:coupled_constant} to find the relation 
between $k$ and $a$ and summing over all the possible values of k,
\begin{gather}
v(x,t) = \int \!\! \mathrm{d}k\,\, C_k e^{\pm i\pi kx}e^{-(k\pi)^2 t}
\end{gather}
To find $C_k$ we use a Fourier transform at time $t=0$,
\begin{gather}
C(k) = \frac{1}{2\pi^2}\int \!\! \mathrm{d}x\,\, 
v(x,0) e^{\mp i\pi kx}
\end{gather}
Setting in the solution for the initial state,
\begin{gather}
C(k) = \frac{1}{2\pi^2}\int_0^1 \!\! \mathrm{d}x\,\,
(x - 1) e^{\pm i\pi kx}
\end{gather}


\section{Discretisation}

Let the spatial domain $x \in [0,d]$ be sampled at $L+1$ points, $x_0,x_1,..,x_i,..,x_L$ and the time be discretised as $t_0,t_1,..,t_n,..,t_N$. Then we denote the solution, $u(x_i,t_n)$, as $u_i^n$.  

\subsection{Explicit Euler}

\begin{gather}
u_i^{n+1} = u_i^n + \frac{\Delta t}{\Delta x^2}\left(
u_{i+1}^n - 2u_i^n + u_{i-1}^n
\right)
\end{gather}
In matrix with boundary conditions
\begin{gather}
u^{n+1} = 
\begin{pmatrix}
1 & 0 & 0 & 0 & \cdots\\
\alpha & 1 - 2\alpha & \alpha & 0 & \cdots\\
0 & \alpha & 1-2\alpha & \alpha & \cdots\\
\cdots & \cdots & \ddots & \ddots& \\
&&& 0 & 1
\end{pmatrix}u^n
\end{gather}


\subsection{Implicit Euler}

Using a backward discretization of the time-derivative we obtain the following finite difference approximation of the diffusion equation:
\begin{align*}
\frac{u_{i}^{n}-u_{i}^{n-1}}{\Delta t} = \frac{u_{i-1}^{n}-2u_{i}^{n}+u_{i+1}^{n}}{\Delta x^2}
\end{align*}
Moving all unknowns to the left hand side and defining $\alpha = \frac{\Delta t}{\Delta x^2}$ we get
\begin{align*}
-\alpha u_{i-1}^n + (1+2\alpha)u_i^n - \alpha u_{i+1}^n = u_i^{n-1}. 
\end{align*}
Let's say we have only five spatial mesh points and Dirichlet boundary conditions, $u(0)=D_0$ and $u(d)=D_1$ , then all the equations reads
\begin{align*}
u_0^n &= D_0 \\
-\alpha u_{0}^n + (1+2\alpha)u_1^n - \alpha u_{2}^n &= u_1^{n-1} \\
-\alpha u_{1}^n + (1+2\alpha)u_2^n - \alpha u_{3}^n &= u_2^{n-1} \\
-\alpha u_{2}^n + (1+2\alpha)u_3^n - \alpha u_{4}^n &= u_3^{n-1} \\
u_L^n &= D_1 
\end{align*}
This now should be recognized as a matrix system on the from, $Au=b$ for 

\begin{align*}
\begin{pmatrix} 1 & 0 & \dots   & \dots         & 0 \\
                -\alpha & 1+2\alpha & -\alpha & 0           &0 \\
        \dots  & \ddots & \ddots & \ddots         & \dots\\
 0   & \dots &  -\alpha & 1+2\alpha & -\alpha \\
 0   & \dots & \dots & \dots    &  1
             \end{pmatrix}
\begin{pmatrix} D_0 \\
      u_1^{n-1} \\
      u_2^{n-1}\\ \dots\\ u_{L-1}^{n-1}\\
      D_1
\end{pmatrix} 
=  \begin{pmatrix} u_0^n \\
                   u_1^n  \\
           \dots\\ \dots\\ \dots\\
                   u_L^n 
             \end{pmatrix} 
\end{align*} 

\subsection{Implicit Crank-Nicolson}
\begin{gather}
u_i^{n+1} = u_i^n + \frac{\Delta t}{2\Delta x^2}\left(
u_{i+1}^n - 2u_i^n + u_{i-1}^n + u_{i+1}^{n+1} - 2u_i^{n+1} + u_{i-1}^{n+1}
\right)
\end{gather}
In matrix
\begin{gather}
u^{n+1} = u^n + \frac{\Delta t}{2\Delta x^2}
\begin{pmatrix}
-2 & 1 & 0\\
1 & -2 & 1\\
0 & 1 & -2
\end{pmatrix} u^n
 + \frac{\Delta t}{2\Delta x^2}
\begin{pmatrix}
-2 & 1 & 0\\
1 & -2 & 1\\
0 & 1 & -2
\end{pmatrix}u^{n+1}\\
s = \alpha/2\\
\begin{pmatrix}
1 & 0 & 0 & 0\\
-\frac{\alpha}{2} & 1 + \alpha & -\frac{\alpha}{2} & 0\\
0 & -\frac{\alpha}{2} & 1 + \alpha & -\frac{\alpha}{2}\\
0 & & \ddots\\
&&& 1
\end{pmatrix}
u^{n+1} = 
\begin{pmatrix}
1 & 0 & 0 & 0\\
\frac{\alpha}{2} & 1 - \alpha & \frac{\alpha}{2} &  0\\
0 & \frac{\alpha}{2} & 1 - \alpha & \frac{\alpha}{2}\\
&& \ddots\\
&&&1
\end{pmatrix}u^n
\end{gather}


\subsection{Specialisation to our problem}

If we consider our problem with ends equal to zero, the schemes can 
be reduced to a submatrix with the ''frame'' not included,
and the operations we need are 
\begin{gather}
d = 
\begin{pmatrix}
a & b & 0 & \cdots\\
b & a & b & \cdots\\
&&\ddots & \ddots\\
&&0& b& a & b\\
&&&&b&a
\end{pmatrix}u
\end{gather}
As both inverse and forward.

\subsection{The $\theta-$scheme}

\section{Error}

To investigate the truncation error in the schemes we look into the approximations we have made deriving them. In order to do that we need the following Taylor series:
\begin{equation}
u(a+h) = u(a) +hu'(a)+O(h^2)
\end{equation}
\begin{equation}
u(a+h) = u(a) +hu'(a)+\frac{1}{2}h^2 u''(a) +O(h^3)
\end{equation}
\begin{equation}
u(a+h/2) = u(a) +\frac{h}{2}u'(a) + \frac{1}{2} \left( \frac{h}{2} \right)^2 u''(a) + O(h^3)
\end{equation}

\subsection{Explicit Euler}
The forward time-derivative is obtained by solving (??) for $u'(a)$, with $a=t$ and $h=\Delta t$
\begin{equation}
\frac{u(t+\Delta t)-u(t)}{\Delta t} = u'(t)+O(\Delta t).
\end{equation}  
Having to divide by $h$ we get an truncation error of $O(h)$ in time.

The second derivative with respect to space is obtained by adding (??), with $a=x$,  $h=\Delta x$ and 
$a=x$,  $h= -\Delta x$ and solving for $u''(x)$:
\begin{equation}
\frac{u(x+\Delta x)-2u(x)+u(x-\Delta x)}{\Delta x^2} = u''(x)+O(\Delta x^2).
\end{equation}  

Using these approximations we have that the truncation error of the Forward Euler scheme is of magnitude $O(\Delta x^2)+O(\Delta t)$.  

\subsection{Implicit Euler}
The error analysis for this scheme is the same as for the forward scheme. One can just set $h=- \Delta t$
instead of $h=\Delta t$ and hence recover the same truncation error, $O(\Delta x^2)+O(\Delta t)$. However, it is "cheaper", computational wise, to obtain more accuracy using this scheme for stability reasons(discussed in section (??)). 

\subsection{Crank-Nicholson}
To ensure better accuracy a center derivative in time can be used as well. By letting $a=t+\Delta t/2$, $h=\Delta t$ and subtracting $a=t-\Delta t/2$, $h=-\Delta t$ for the series (??) we get the following center time-derivative:
\begin{equation}
\frac{u(t + \Delta t)-u(t)}{\Delta t} = u'(t+\Delta t) + O(\Delta t^2)
\end{equation}
Having evaluated the time-derivative in $t+\Delta t$ we must evaluate the spatial-derivative in between time-points. That can be done by using an arithmetic mean of the two closest time-points
\begin{align*}
u(t+\Delta t/2) \simeq \frac{1}{2}(u(t)+u(t+\Delta t)).
\end{align*}
Using approximation above combined with expression for the second order derivative we get a truncation error of $O(\Delta x^2)+O(\Delta t^2)$ for the Crank-Nicholson scheme. 


\section{Stability}

The key to our stability analysis is to investigate how the numerical solution grows(or in the case of diffusion; decays) compared to the analytical. This will be done by using the known analytical solution on the form:
\begin{equation}
u(x,t) = T(t)e^{ik \pi x} = e^{-(k\pi)^t}e^{ik \pi x}
\end{equation}
The solution consists of a periodic wave component, and a component decaying in time, $T(t)=e^{-(k\pi)^t}$. We will define a discrete solution on the form
\begin{equation}
v^n_i = A^n e^{ik \pi x_i}
\end{equation}
and insert it into the different discrete equations(schemes) and see what restrictions this puts on $\Delta x$ and $\Delta t$ (\emph{i} sub-script is discrete spatial position, not the imaginary unit as in the wave component).

This form of analysis is known as \emph{Von Neumann's stability analysis}.

\subsection{Explicit Euler}

By inserting the discrete solution, $v^n_i$, into the explicit Euler scheme we get
\begin{align*}
\frac{A^{n+1}-A^{n}}{\Delta t} e^{ik \pi x_i} = \frac{e^{ik \pi x_{i+1}} -2e^{ik \pi x_i} + e^{ik \pi x_{i-1}}}{\Delta x^2} A^n.
\end{align*}
If we now use the fact that $x_i = i\Delta x$ and divide both sides by $A^n e^{ik \pi x_i}$ we obtain the simpler equation
\begin{align*}
\frac{A-1}{\Delta t} = \frac{e^{ik \pi \Delta x} -2 + e^{-ik \pi \Delta x}}{\Delta x^2} = -\frac{4}{\Delta x^2}sin^2\left(k\pi \frac{\Delta x}{2}\right)
\end{align*}
which solved for $A$ gives
\begin{align*}
A=1-\frac{4\Delta t}{\Delta x^2}sin^2\left(k\pi \frac{\Delta x}{2}\right).
\end{align*}
Now, since $T(0)=1$ and $T(t)$ is decaying we must have that $|A| \leq 1$, that is, from the expression above, 
\begin{align*}
\abs{ \frac{4\Delta t}{\Delta x^2}sin^2\left(k\pi \frac{\Delta x}{2}\right)} \leq 2
\end{align*} 
which is satisfied for $\frac{\Delta t}{\Delta x^2} \leq \frac{1}{2}$. The scheme is so called \emph{conditionally stable}.

\subsection{Implicit Euler}
We follow the same reasoning and procedure as for explicit Euler and start by inserting the discrete solution, $v^n_i$, into the scheme:
\begin{align*}
\frac{A^{n}-A^{n-1}}{\Delta t} e^{ik \pi x_i} = \frac{e^{ik \pi x_{i+1}} -2e^{ik \pi x_i} + e^{ik \pi x_{i-1}}}{\Delta x^2} A^n.
\end{align*}
If we now use the fact that $x_i = i\Delta x$ and divide both sides by $A^n e^{ik \pi x_i}$ we obtain the simpler equation
\begin{align*}
\frac{1-A^{-1}}{\Delta t} = \frac{e^{ik \pi \Delta x} -2 + e^{-ik \pi \Delta x}}{\Delta x^2} = -\frac{4}{\Delta x^2}sin^2\left(k\pi \frac{\Delta x}{2}\right)
\end{align*}
which solved for $A$ gives
\begin{align*}
A=\left( \frac{4\Delta t}{\Delta x^2}sin^2\left(k\pi \frac{\Delta x}{2}\right)-1 \right)^{-1}.
\end{align*}
Again we require that $|A| \leq 1$, which this time puts no restrictions on the $\Delta t/ \Delta x^2$ relationship. This is therefore a so called \emph{unconditionally stable} scheme.


\subsection{Crank-Nicholson}
To quote the cult television classic \emph{Dinner for one}:  \emph{"Same procedure as every year, James!}

Inserting  $v^n_i$, into the Crank-Nicholson scheme
\begin{align*}
\frac{A^{n+1} - A^{n}}{\Delta t} e^{ik \pi x_i} = \frac{1}{2} \left( \frac{e^{ik \pi x_{i+1}}-2e^{ik \pi x_{i}} + e^{ik \pi x_{i-1}}}{\Delta x^2} (A^n + A^{n+1})  \right)
\end{align*}
which can be written 
\begin{align*}
\frac{A-1}{\Delta t} &= \frac{1}{2} \left( \frac{e^{ik \pi \Delta x} -2 + e^{-ik \pi \Delta x}}{\Delta x^2} (1 + A) \right) \\
&= \frac{1}{2} \left( -\frac{4}{\Delta x^2}sin^2\left(k\pi \frac{\Delta x}{2}\right)(1 + A) \right).
\end{align*}
Solving this equation for $A$
\begin{align*}
A = \frac{1-\frac{2\Delta t}{\Delta x^2}sin^2\left(k\pi \frac{\Delta x}{2}\right)}{1+\frac{2\Delta t}{\Delta x^2}sin^2\left(k\pi \frac{\Delta x}{2}\right)}
\end{align*}
we see that $|A| \leq 1$ is fulfilled, and the scheme is  \emph{unconditionally stable}.




\section{Sparse matrix}
The matrices encountered in the solvers are very sparse, with the same 
diagonal element and off-diagonals. In order to maximize performance 
we implement solvers for the necessary operations.

There are two methods implemented for each method, one inplace and one 
to a new vector

\subsection{Multiplication}
\begin{equation}
d = Au =
\begin{pmatrix}
a & b & 0 & 0\\
b & a & b & 0\\
0 & b & a & b\\
\cdots & & b & a
\end{pmatrix}u
\end{equation}

\begin{algorithm}
\begin{enumerate}[label=\bfseries \arabic*)]
\item Get initial vector u, and the numbers a and b
\item Allocate a new vector d
\item make a loop over all but the ends,
\begin{gather*}
d_i = bu_{i-1} + au_i + bu_{i+1}
\end{gather*}
\item Take care of the ends, 
\begin{align*}
 d_1 &= ad_0 + bd_1\\
 d_{end} &= bd_{end -1} + ad_{end}
\end{align*}
\end{enumerate}
\end{algorithm}


\subsection{Inverse matrix multiplication}
We have the equation 
\begin{gather}
d = Au
\end{gather}
with d and A known, where A is a supersparse matrix. Adapting the 
tridiagonal matrix algorithm from project 1,
\begin{algorithm}
\begin{enumerate}[label=\bfseries \arabic*)]
\item Use TDMA from project 1
\end{enumerate}
\end{algorithm}

\section{Algorithm}
A standard matrix
\begin{gather}
A = \begin{pmatrix} a & b & 0&\cdots\\
		    b & a & b & 0&\cdots\\
		    0 &b&a&b& 0&\cdots\\
		    \vdots&0&\ddots&\ddots&\ddots\\
		    &\vdots&&\\
		    &&\cdots&0&b&a
    \end{pmatrix}
    \label{eq:matrixA}
\end{gather}


\subsection{Explicit Euler}
\begin{algorithm}
\begin{enumerate}[label=\bfseries \arabic*)]
\item Calculate
\begin{gather*}
\alpha = \frac{\Delta t}{\Delta x^2}\\
a = 1 - \alpha\\
b = \alpha
\end{gather*}
\item Mulitply $u^n$ with the matrix A, \eqref{eq:matrixA}
\item Repeat for the next time-step
\end{enumerate}
\end{algorithm}

\subsection{Implicit Euler}
\begin{algorithm}
\begin{enumerate}[label=\bfseries \arabic*)]
\item Calculate
\begin{gather*}
\alpha = \frac{\Delta t}{\Delta x^2}\\
a = 1 + \alpha\\
b = -\alpha
\end{gather*}
\item Solve the matrix equation $d = Au$ with A as \eqref{eq:matrixA},
and $d$ as $u^n$ using TDMA. The solution is $u^{n+1}$

\item Repeat for the next time-step
\end{enumerate}
\end{algorithm}

\subsection{Crank Nicholson}

\begin{algorithm}
\begin{enumerate}[label=\bfseries \arabic*)]
\item Calculate
\begin{gather*}
\alpha = \frac{1}{2}\frac{\Delta t}{\Delta x^2}\\
a_1 = 1 - \alpha, \quad
b_1 = \alpha\\
a_2 = 1 + \alpha, \quad
b_2 = -\alpha
\end{gather*}

\item Do a matrix multiplication with $u^n$ and $A_1$, where $A_1$ has 
the entries $a_1$ and $b_1$ on the form of \eqref{eq:matrixA}.

\item Do an inverse matrix multiplication with $A_2$, where $A_2$ has 
the entries $a_2$ and $b_2$

\item Repeat for the next time-step

\end{enumerate}
\end{algorithm}


\end{document}